## Example: Getting Better Results by Adjusting Parameters
```
Okay, we've covered the various ways that you can evaluate the responses from an AI model. Now let's go through an example together of how we can tweak the parameters to get different or better output. And by parameters, I mean, these things that we've seen several times throughout the course. We're going to start with just a simple prompt so we don't get too bogged down in a lot of facts. The inventor of the iPhone is, let's move this over to the playground. Here we go. Over on the right, I'm starting with a Temperature of 0, meaning we'll have low variability and creativity in this response. Let's just submit this response and see what we get as a starter. Okay, the inventor of the iPhone is Steve Jobs, getting some additional information there about Steve Wozniak and so on. Now one really handy parameter that you can use is over here on the very lower right to Show probabilities. This will highlight your words and tell you what the probability was that that word was the one that would be chosen. Remember with large language models, they're really just predicting what word comes next, one word at a time. So let me toggle this On and make it a little bit easier to understand. We'll go with Full spectrum, and then we'll run this again. I'll just get rid of this response and then submit. So we're getting basically the same response, but now you can see that as you click on the different words here, it'll tell us the probability that it calculated for which word to place next. In this case, the word Steve won with 97.3%. And then some of the other words that were considered here, but obviously, a much lower probability on those. We can look at some of these others here like Apple 52.44%, but it won obviously. And you can look at some of the other words here as well. Just click on anything in the response and find out what that probability was. So it's just making predictions. Now, let's play with some of these other parameters over here on the right. Let's dial up the Temperature a little bit. We started with 0, so let's dial this up to 1 to get a little bit more creativity and variability in the response. We'll run the prompt again. I'll get rid of what we had, and let's see what we get this time. We do still have the token highlighting on. And with that, we can actually see some words here that are highlighted in red. So if we look at market, for example, this wasn't the highest probability or the highest percentage, but it still chose it. So the model is taking a little bit more risk with this temperature setting and including some other words. When we had Temperature set to 0, it would have chosen this one up here, public for 97.69%, but we're going with market down here. If we look at some of these other words here, you'll see introduced is also a lower percentage. So the model is taking a little bit more risk with this setting. We can also adjust some of these other parameters. Let's take a look at the Frequency penalty and Presence penalty. For the Frequency penalty, if we increase this, the model should avoid using the same phrases, which makes things more unique and more engaging. Let's bump this up to say a 0.5. And then with Presence penalty, the model should use words it wouldn't typically use, so we're going to get more detailed and diverse descriptions. Kind of similar to Temperature, but a little bit different. Let's bump this up to 0.5 as well, and then let's see the difference. So I'll get rid of our response, we'll start over. So we see there's more diversity in the words. And with the color tagging, we can see it's also still taking a little bit more risk. It's not always choosing the word with the highest probability. We have more pink and red highlights here. If we were to bump up the Temperature as high as it will go, up to 2 and try this again, now we're just kind of getting gibberish. This isn't coherent or clear or factually correct or anything else, so way too much creativity, lots of words that are in red. And if we were doing an evaluation on this, we would know that we need to dial back that Temperature so we can get more realistic answers. So those are some of the knobs and levers that you can use to iterate through the model responses, evaluate the different settings, tweak a few things until you get it just right. Now let's summarize the module.
```

## Notes
Alright, here's a summary of adjusting model parameters for better responses:

### Model Parameters and their Impact:
- **Temperature:** Controls creativity and variability in responses. Higher values lead to more diverse, riskier, sometimes less coherent output.
- **Frequency Penalty:** Increasing it prevents repetitive phrases, enhancing uniqueness and engagement in responses.
- **Presence Penalty:** Higher values encourage the use of less typical words, enriching descriptions and diversity.
- **Show Probabilities:** Helps visualize word selection probabilities, showcasing the likelihood of each word chosen by the model.

### Example Iteration with Parameters:
1. **Temperature (0 to 2):**
   - Low (0): Predictable, factual responses.
   - High (2): Unstructured, less coherent, and unrealistic output.

2. **Frequency & Presence Penalty:**
   - Increased values promote varied vocabulary and uniqueness in responses.
   - Higher settings generate more diverse and detailed descriptions.

### Evaluation and Adjustment:
- **Visualizing Probabilities:** Highlighting word selection percentages aids in understanding model choices.
- **Tweaking Parameters:** Iterate through settings, evaluate responses, and adjust parameters to achieve desired output quality.

This hands-on walkthrough demonstrates how tweaking parameters like Temperature, Frequency Penalty, and Presence Penalty influences response quality. Evaluating the impact of these changes helps fine-tune the model for more accurate and coherent results.
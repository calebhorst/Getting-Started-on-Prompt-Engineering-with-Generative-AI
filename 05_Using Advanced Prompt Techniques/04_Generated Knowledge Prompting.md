## Generated Knowledge Prompting
```
The next type of prompting is called generated knowledge. This is basically where you feed in additional knowledge or context to improve the performance of complex tasks like reasoning. We can first ask a question to establish the model's baseline understanding or response and see what kind of answer we get. For example, what would happen if the moon disappeared? Assuming the answer is less than perfect, we can then feed in additional knowledge. So we've got three different points here about the earth and the tides and the moon. And then we can ask the question again. This time, hopefully, we'll get an answer that we're looking for. And you can iterate and continue to give it new knowledge until it's been properly trained and is giving appropriate responses. Here's another example that's super helpful for developers out there, the ability to give it knowledge from API documentation. So APIs are changing all the time. There's new ones out there as well. So chances are the model's training data is a little bit out of date. But not to worry. You can just feed in the documentation from the API. In this example, we would pass in documentation from an endpoint that converts between currencies, and then we're asking for a Java method to call that code. Lets see this one in the playground. So here's the documentation, and then I just went out and found an API that is currency conversion. And specifically, the endpoint we want is convert endpoint. So we can just copy and paste this. We select everything here, including an example of the response, the different objects. I'll copy and paste this into the playground here after the delimiter. Looking good. And then we'll hit Submit and see what we get. All right, here's our Java method. It's writing a function to convert currency. It knows we need an API key and knows the different things that we're going to send in, the things that we're going to get back, and so on. So the model didn't know anything about this API endpoint until we gave it that knowledge. So we're basically helping it generate new knowledge to get the response that we want.
```

## Notes
Absolutely, summarizing "generated knowledge" in prompt engineering:

- **Generated knowledge:** Involves enhancing an AI model's performance by providing it with additional context, information, or documentation related to a specific task or problem. It's a way to expand the model's understanding or abilities beyond its existing training data.

- **Context enrichment for better responses:** By initially testing the AI's baseline understanding through a question or task, one can evaluate its performance. If the response is insufficient or incorrect, additional knowledge or context can be fed into the model.

- **Iterative improvement:** The process involves an iterative approach where the model is provided with new information or data, enabling it to offer more accurate or improved responses. This cycle of providing new knowledge, evaluating the response, and refining the model's understanding can continue until the desired outcomes are achieved.

- **API documentation utilization:** Particularly beneficial for developers, this technique involves using API documentation to enhance the model's knowledge about specific functionalities or operations within an API. By feeding the model with information from API documentation, it can generate code or perform tasks aligned with the given API, even if it wasn't previously familiar with that specific API endpoint or functionality.

The examples demonstrated how feeding the AI model additional knowledge or documentation can significantly enhance its performance and capabilities, allowing it to generate more accurate or tailored responses in various domains, from answering complex questions to generating code based on specific API endpoints.